{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoEFSXNDN4ju"
   },
   "source": [
    "# Entrenamiento de Autoencoders con datos de dígitos (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKwAmM2mNgEF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XssZbuDSOEI1"
   },
   "source": [
    "## Carga y procesamiento de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0fBxO1COFIl"
   },
   "outputs": [],
   "source": [
    "# Carga\n",
    "(X_train, y_train), (X_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "print(' -Entradas Entrenamiento:', X_train.shape)\n",
    "print(' -Entradas Test:', X_test.shape)\n",
    "\n",
    "# Normalización\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print('Cambio de dimensiones para ajustar a la entrada de un Perceptrón:')\n",
    "x_shape = X_train.shape\n",
    "X_train = X_train.reshape(x_shape[0], x_shape[1]*x_shape[2])\n",
    "X_test = X_test.reshape(len(X_test), x_shape[1]*x_shape[2])\n",
    "print(' -Entradas Entrenamiento:', X_train.shape)\n",
    "print(' -Entradas Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9l_RuFtOc9n"
   },
   "source": [
    "## Autoencoder profundo\n",
    "### Creación del autoencoder\n",
    "Vamos a crear un autoencoder que codifique y decodifique la entrada de 728 píxeles en la siguiente secuencia de dimensiones:\n",
    "\n",
    "784 → 128 → 64 → 32 → 64 → 128 → 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi1nIAg7Oafu"
   },
   "outputs": [],
   "source": [
    "# Tamaño de nuestra representación codificada\n",
    "encoding_dim = 32  # Factor de compresión = 24.5 (dado que la entrada es de tamaño 784)\n",
    "\n",
    "# Definimos las capas para la entrada, el encoder y el decoder:\n",
    "# Capa de entrada\n",
    "input_img = . . .\n",
    "\n",
    "# Capas del encoder\n",
    "#      .\n",
    "#      .\n",
    "#      .\n",
    "\n",
    "# Capas del decoder\n",
    "#      .\n",
    "#      .\n",
    "#      .\n",
    "\n",
    "#       Autoencoder\n",
    "# --------------------------\n",
    "# \"encoded\" es la representación codificada de la entrada (cada vez más comprimida)\n",
    "encoded = . . .\n",
    "#      .\n",
    "#      .\n",
    "#      .\n",
    "\n",
    "\n",
    "# \"decoded\" es la reconstrución de la entrada a partir de la entrada codificada\n",
    "decoded = . . .\n",
    "#      .\n",
    "#      .\n",
    "#      .\n",
    "\n",
    "# Modelo que reconstruye una entrada\n",
    "autoencoder = tf.keras.Model(input_img, decoded)\n",
    "\n",
    "# Visualizar arquitectura y dimensiones\n",
    "print(f\"{'*'*65}\\n\\t\\t\\tAutoencoder\\n{'*'*65}\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIRkVdivQ8qL"
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nblNVZF3Q8Cl"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='')\n",
    "hist= autoencoder.fit(, \n",
    "                      ,\n",
    "                      epochs=50,\n",
    "                      batch_size=256,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ud9za_Rx3Z2u"
   },
   "source": [
    "### Evaluación y visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmX4QIq59nKc"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Error')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Entrenamiento', 'Validación']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JAmGvpcs0_r"
   },
   "outputs": [],
   "source": [
    "# Vamos a crear ahora por un lado un modelo para el encoder y otro para el decoder\n",
    "#          Encoder\n",
    "# ------------------------\n",
    "encoder = tf.keras.Model(, )\n",
    "\n",
    "# Visualizar arquitectura y dimensiones\n",
    "print(f\"\\n{'*'*65}\\n\\t\\t\\tEncoder\\n{'*'*65}\")\n",
    "encoder.summary()\n",
    "\n",
    "# Codificamos y decodificamos algunos dígitos de ejemplo (datos de test)\n",
    "# -----------------------\n",
    "encoded_imgs = . . .\n",
    "decoded_imgs = . . .\n",
    " \n",
    "n_images = 10 \n",
    "plt.figure(figsize=(30, 4))\n",
    "for i in range(n_images):\n",
    "    # Entrada (original)\n",
    "    plt.subplot(3, n_images, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title('Entrada')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Codificación\n",
    "    plt.subplot(3, n_images, i + 1 + n_images)\n",
    "    plt.imshow(encoded_imgs[i].reshape(1, encoding_dim), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Entrada codificada')\n",
    "    \n",
    "    # Reconstrucción\n",
    "    plt.subplot(3, n_images, i + 1 + n_images + n_images)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Reconstrucción')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_F7bIhs3fCN"
   },
   "source": [
    "## Aplicación: Eliminación de ruido\n",
    "Para obtener un modelo capaz de eliminar ruido de las imágenes de dígitos vamos a entrenar un autoencoder que mapee imágenes de dígitos con ruido (entrada) a imágenes de dígitos \"limpias\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4ms-kNx3tZG"
   },
   "outputs": [],
   "source": [
    "# Añadimos ruido gaussiano (distribución normal) a las imágenes.\n",
    "noise_factor = 0.5\n",
    "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
    "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "\n",
    "# Aseguramos que todos los pixeles queden en el rango [0, 1]\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
    "\n",
    "# Dibujamos las imágenes con ruido\n",
    "n_images = 10\n",
    "plt.figure(figsize=(30, 3))\n",
    "for i in range(n_images):\n",
    "    plt.subplot(1, n_images, i+1)\n",
    "    plt.imshow(X_test_noisy[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DP5x2WdhAZo7"
   },
   "source": [
    "### Creación del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnDxX8xYAY6d"
   },
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "encoding_dim = 32\n",
    "autoencoder = tf.keras.models.Sequential()\n",
    "#       .\n",
    "#       .\n",
    "#       .\n",
    "\n",
    "# Entrenamiento\n",
    "autoencoder.compile(optimizer='adam', loss='')\n",
    "hist= autoencoder.fit(, \n",
    "                      ,\n",
    "                      epochs=50,\n",
    "                      batch_size=256,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(, ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJVpDdoJC27n"
   },
   "source": [
    "### Evaluación y visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cr5V5UOgC-OV"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Error')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Entrenamiento', 'Validación'])\n",
    "\n",
    "predictions = autoencoder.predict(X_test)\n",
    "n_images = 10 \n",
    "plt.figure(figsize=(30, 8))\n",
    "for i in range(n_images):\n",
    "    # Entrada (original)\n",
    "    plt.subplot(3, n_images, i + 1)\n",
    "    plt.imshow(X_test_noisy[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title('Entrada')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Reconstrucción\n",
    "    plt.subplot(3, n_images, i + 1 + n_images)\n",
    "    plt.imshow(predictions[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Reconstrucción')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0igVc6GhgJF"
   },
   "source": [
    "## Autoencoder Variacional\n",
    "### Creación del Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3MI8YrlBK_h"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    # Capas del encoder\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "\n",
    "  def call(self, inputs, training=None, mask=None):\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3OWaMRyyfff"
   },
   "source": [
    "### Creación de la capa que representa la distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9spiM1SnyrZH"
   },
   "outputs": [],
   "source": [
    "class NormalDistribution(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(NormalDistribution, self).__init__()\n",
    "    \n",
    "    # Capas\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "\n",
    "  def call(self, inputs, training=None, mask=None):\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "    return z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aACxBKvohkXO"
   },
   "source": [
    "\n",
    "### Creación de la capa de muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qtElIDFhpUr"
   },
   "outputs": [],
   "source": [
    "class Reparametrize(tf.keras.layers.Layer):\n",
    "  \"\"\"\n",
    "  Usa (z_mu, z_log_var) para muestrear z (el vector que \n",
    "  representa el dígito codificado)\n",
    "  \"\"\"\n",
    "  def call(self, inputs):\n",
    "    z_mu, z_log_var = inputs\n",
    "    \n",
    "    # Extraemos dimensiones (del batch y del espacio codificado)\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "    \n",
    "    # Muestreamos de una distribucion normal ϵ: con dimensiones (batch, dim_spacio_codificado)\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "    \n",
    "    # Transformamos log(σ^2) en σ \n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "\n",
    "    # Truco de re-parametrización\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "    \n",
    "    return reparametrization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FL1FirsoCtKy"
   },
   "source": [
    "### Creación del Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-iYljRwBnIz"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    # Capas del decoder\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "\n",
    "  def call(self, inputs,  training=None, mask=None):\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKQzo-txsLoc"
   },
   "source": [
    "### Creación de la función de coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLcf71NqsKra"
   },
   "outputs": [],
   "source": [
    "class LossVAE(tf.keras.layers.Layer):\n",
    "  \"\"\"\n",
    "  Función de error custom: suma del término de reconstrucción y \n",
    "  el término de regularización KL divergence\n",
    "  \"\"\"\n",
    "  def call(self, inputs):\n",
    "    y_true, y_pred, z_mean, z_log_var = inputs\n",
    "    \n",
    "    # Error de reconstrucción (usa categorical_crossentroy)\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "    \n",
    "    # Divergencia KL\n",
    "    #       .\n",
    "    #       .\n",
    "    #       .\n",
    "  \n",
    "    return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx9qBX37CzeY"
   },
   "source": [
    "### Creación del Autoencoder Variacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIPYLV1uhmHj"
   },
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "      super(VAE, self).__init__()\n",
    "      # Capas del VAE\n",
    "      #       .\n",
    "      #       .\n",
    "      #       .\n",
    "\n",
    "    def call(self, inputs,  training=None, mask=None):\n",
    "      #       .\n",
    "      #       .\n",
    "      #       .\n",
    "      return (z_mean, z_log_var, z), decoded\n",
    "\n",
    "    def train_step(self, data):\n",
    "      with tf.GradientTape() as tape:\n",
    "        # Propagación hacia delante\n",
    "        #       .\n",
    "        #       .\n",
    "        #       .\n",
    "        \n",
    "        # Error Loss VAE\n",
    "        #       .\n",
    "        #       .\n",
    "        \n",
    "      # Retro-propagación\n",
    "      grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "      \n",
    "      # Actualización de los pesos\n",
    "      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "      \n",
    "      return {\"total_loss\": total_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4k9tjKAQ7wo"
   },
   "source": [
    "### Entrenamiento del Autoencoder Variacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYCno6nA4vGU"
   },
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(X_train, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvUZD_JsRIE_"
   },
   "source": [
    "### Muestra de Dígitos Generados con el Autoencoder Varacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jbk67dUWRo6v"
   },
   "outputs": [],
   "source": [
    "def plot_latent(model, fig_size=15, scale=3.):\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # Creamos un grid 2D linealmente espaciado correspondiente a\n",
    "    # los dígitos en el espacio codificado\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            # Para cada coordenada 2D del espacio codificado, \n",
    "            # usamos el decoder para reconstruir/generar una imagen nueva.\n",
    "            x_decoded = model.decoder(z_sample).numpy()\n",
    "            digit = x_decoded.reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size : (i + 1) * digit_size,\n",
    "                   j * digit_size : (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(fig_size, fig_size))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_label_clusters(model, data, labels, fig_size=15, scale=3.):\n",
    "    # Dibujamos un plot 2D the los dígitos y sus clases en el espacio codificado\n",
    "    encoded = model.encoder(data)\n",
    "    z_mean, _ = model.normal_distribution(encoded)\n",
    "    plt.figure(figsize=(fig_size, fig_size))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.xlim((-scale, scale))\n",
    "    plt.ylim((-scale, scale)) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaGwFRoRY2vU"
   },
   "outputs": [],
   "source": [
    "plot_latent(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgOm9S0jk5S3"
   },
   "outputs": [],
   "source": [
    "plot_label_clusters(vae, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPboRLZGYr2/H0iCK0kfe+o",
   "collapsed_sections": [],
   "name": "autoencoders_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
